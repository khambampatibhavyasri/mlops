image: python:3.10-slim

variables:
  PIP_CACHE_DIR: "$CI_PROJECT_DIR/.cache/pip"
  PIP_DISABLE_PIP_VERSION_CHECK: "1"
  PIP_NO_INPUT: "1"
  PYTHONUNBUFFERED: "1"

cache:
  key: ${CI_COMMIT_REF_SLUG}
  paths:
    - .cache/pip
    - .dvc/cache

stages: [setup, train, automl, push]

# ---------- reusable setup ----------
.setup:
  stage: setup
  before_script:
    # Git can refuse if repo owner UID != runner UID
    - git config --global --add safe.directory "$CI_PROJECT_DIR"
    - apt-get update && apt-get install -y --no-install-recommends git gcc g++ build-essential libgomp1 curl && rm -rf /var/lib/apt/lists/*
    - python -m pip install -U pip wheel setuptools
    - pip install -r requirements.txt --no-cache-dir
    # DVC auth to DAGsHub (writes .dvc/config.local)
    - dvc remote list || true
    - dvc remote modify origin auth basic
    - dvc remote modify origin --local user "$DAGSHUB_USER"
    - dvc remote modify origin --local password "$DAGSHUB_TOKEN"
    - echo "MLFLOW_TRACKING_URI=${MLFLOW_TRACKING_URI}"
    - echo "Branch=${CI_COMMIT_BRANCH} Commit=${CI_COMMIT_SHORT_SHA}"
    # If your raw data is DVC-tracked, this pulls it; if raw is in Git, this is a no-op
    - dvc pull || true
  artifacts:
    when: always
    expire_in: 1 week
    paths:
      - .dvc/config.local
      - .cache/pip
  rules:
    - when: always

# ---------- prove setup is good ----------
setup:
  extends: .setup
  script:
    - python -c "import sys; print('Python', sys.version)"
    - dvc version
    - python - << 'PY'
from mlflow import get_tracking_uri
print("MLflow tracking URI:", get_tracking_uri())
PY

# ---------- baseline train (fast, required) ----------
train:
  extends: .setup
  stage: train
  needs: ["setup"]
  script:
    # Sanity: raw file exists?
    - ls -al data || true
    - ls -al data/raw || true
    - test -f data/raw/sales.csv && echo "Found raw sales.csv" || echo "WARNING: data/raw/sales.csv missing (ensure it's committed or DVC-tracked)"
    # Show which MLflow store is active
    - python - << 'PY'
import mlflow
print("Using MLflow URI:", mlflow.get_tracking_uri())
PY
    # Reproduce only train stage (ingest/features will run if needed)
    - dvc repro train -v
    # Print link to the latest MLflow run
    - python - << 'PY'
import os, mlflow
from mlflow.tracking import MlflowClient
exp = mlflow.get_experiment_by_name("retail-sales")
if exp:
    c = MlflowClient()
    runs = c.search_runs([exp.experiment_id], order_by=["attributes.start_time DESC"], max_results=1)
    if runs:
        run = runs[0]
        uri = os.getenv("MLFLOW_TRACKING_URI")
        link = f"{uri}/#/experiments/{exp.experiment_id}/runs/{run.info.run_id}" if uri and uri.startswith("http") else "(local file store)"
        print("Latest 'retail-sales' run:", run.info.run_id)
        print("Open DAGsHub run:", link)
    else:
        print("No runs found in 'retail-sales'.")
else:
    print("Experiment 'retail-sales' not found. Did the script log a run?")
PY
  artifacts:
    expire_in: 1 week
    paths:
      - dvc.lock
      - models/
      - reports/
      - data/processed/

# ---------- AutoML (manual, optional, won't fail pipeline) ----------
automl:
  extends: .setup
  stage: automl
  needs: ["train"]
  when: manual
  allow_failure: true
  script:
    - python - << 'PY'
import mlflow
print("Using MLflow URI:", mlflow.get_tracking_uri())
PY
    - dvc repro automl_pycaret -v
    - python - << 'PY'
import os, mlflow
from mlflow.tracking import MlflowClient
exp = mlflow.get_experiment_by_name("pycaret-regression")
if exp:
    c = MlflowClient()
    runs = c.search_runs([exp.experiment_id], order_by=["attributes.start_time DESC"], max_results=1)
    if runs:
        run = runs[0]
        uri = os.getenv("MLFLOW_TRACKING_URI")
        link = f"{uri}/#/experiments/{exp.experiment_id}/runs/{run.info.run_id}" if uri and uri.startswith("http") else "(local file store)"
        print("Latest 'pycaret-regression' run:", run.info.run_id)
        print("Open DAGsHub run:", link)
    else:
        print("No runs found in 'pycaret-regression'.")
else:
    print("Experiment 'pycaret-regression' not found. Did the script log a run?")
PY
  artifacts:
    expire_in: 1 week
    paths:
      - dvc.lock
      - models/
      - reports/

# ---------- push DVC artifacts to DAGsHub (required) ----------
push_dvc:
  extends: .setup
  stage: push
  needs: ["train"]   # don't block on automl (manual)
  script:
    - dvc remote list
    - dvc status -c || true
    - dvc push -v
    - dvc status -c
